const axios = require('axios');

class OllamaService {
  constructor() {
    this.baseURL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
    this.defaultModel = process.env.OLLAMA_DEFAULT_MODEL || 'llama3';
    this.timeout = 60000; // Longer timeout for local processing
    this.isAvailable = false;
    this.checkAvailability();
  }

  async checkAvailability() {
    try {
      const response = await axios.get(`${this.baseURL}/api/tags`, {
        timeout: 5000
      });
      this.isAvailable = true;
      console.log('âœ… Ollama service is available');
      if (response.data.models && response.data.models.length > 0) {
        console.log(`ðŸ“¦ Available models: ${response.data.models.map(m => m.name).join(', ')}`);
      }
    } catch (error) {
      this.isAvailable = false;
      console.warn('âš ï¸  Ollama service not available. Make sure Ollama is running with: ollama run llama3');
    }
  }

  async generateText(prompt, model = this.defaultModel) {
    if (!this.isAvailable) {
      throw new Error('Ollama service not available. Please start Ollama with: ollama run llama3');
    }

    try {
      const response = await axios.post(`${this.baseURL}/api/generate`, {
        model: model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          max_tokens: 1000
        }
      }, {
        timeout: this.timeout
      });

      return response.data.response;
    } catch (error) {
      console.error('Ollama API error:', error.message);
      throw new Error(`Ollama generation failed: ${error.message}`);
    }
  }

  async analyzeEvents(events) {
    if (!this.isAvailable) {
      throw new Error('Ollama service not available');
    }

    try {
      const eventSummary = events.map(event => ({
        binId: event.bin_id,
        fillLevel: event.fill_level,
        weight: event.weight,
        timestamp: event.timestamp,
        location: event.location
      }));

      const prompt = `Analyze the following smart bin events and provide insights:

Events: ${JSON.stringify(eventSummary, null, 2)}

Please provide analysis in the following JSON format:
{
  "insights": [
    {
      "type": "capacity_optimization|usage_pattern|anomaly|efficiency",
      "description": "Detailed insight description",
      "severity": "low|medium|high",
      "recommendation": "Actionable recommendation"
    }
  ],
  "summary": "Overall analysis summary",
  "trends": {
    "fill_level_trend": "increasing|decreasing|stable",
    "weight_trend": "increasing|decreasing|stable",
    "usage_frequency": "high|medium|low"
  }
}`;

      const response = await this.generateText(prompt);
      
      try {
        // Try to parse JSON from response
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          return JSON.parse(jsonMatch[0]);
        } else {
          // Fallback: create structured response from text
          return {
            insights: [{
              type: 'ai_analysis',
              description: response,
              severity: 'medium',
              recommendation: 'Review the AI analysis for actionable insights'
            }],
            summary: response.substring(0, 200) + '...',
            trends: {
              fill_level_trend: 'stable',
              weight_trend: 'stable',
              usage_frequency: 'medium'
            }
          };
        }
      } catch (parseError) {
        console.warn('Failed to parse Ollama response as JSON, using text fallback');
        return {
          insights: [{
            type: 'ai_analysis',
            description: response,
            severity: 'medium',
            recommendation: 'Review the AI analysis for actionable insights'
          }],
          summary: response.substring(0, 200) + '...',
          trends: {
            fill_level_trend: 'stable',
            weight_trend: 'stable',
            usage_frequency: 'medium'
          }
        };
      }
    } catch (error) {
      console.error('Ollama event analysis failed:', error.message);
      throw error;
    }
  }

  async analyzeSingleEvent(event) {
    if (!this.isAvailable) {
      throw new Error('Ollama service not available');
    }

    try {
      const prompt = `Analyze this single smart bin event:

Event: ${JSON.stringify(event, null, 2)}

Provide analysis in JSON format:
{
  "anomaly_score": 0.0-1.0,
  "is_anomaly": true/false,
  "anomaly_type": "fill_level|weight|timing|location",
  "description": "Analysis description",
  "recommendation": "Action recommendation"
}`;

      const response = await this.generateText(prompt);
      
      try {
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          return JSON.parse(jsonMatch[0]);
        } else {
          return {
            anomaly_score: 0.5,
            is_anomaly: false,
            anomaly_type: 'none',
            description: response,
            recommendation: 'Review the analysis'
          };
        }
      } catch (parseError) {
        return {
          anomaly_score: 0.5,
          is_anomaly: false,
          anomaly_type: 'none',
          description: response,
          recommendation: 'Review the analysis'
        };
      }
    } catch (error) {
      console.error('Ollama single event analysis failed:', error.message);
      throw error;
    }
  }

  async getPredictiveAnalytics(binId, historicalData) {
    if (!this.isAvailable) {
      throw new Error('Ollama service not available');
    }

    try {
      const prompt = `Based on this historical data for bin ${binId}, provide predictive analytics:

Historical Data: ${JSON.stringify(historicalData, null, 2)}

Provide predictions in JSON format:
{
  "capacity_forecast": {
    "next_24h": "percentage",
    "next_week": "percentage",
    "next_month": "percentage"
  },
  "collection_optimization": {
    "optimal_frequency": "daily|weekly|bi-weekly",
    "next_collection": "timestamp",
    "efficiency_score": 0.0-1.0
  },
  "usage_patterns": {
    "peak_hours": ["hour1", "hour2"],
    "peak_days": ["day1", "day2"],
    "seasonal_trends": "description"
  },
  "revenue_forecast": {
    "daily_average": "amount",
    "weekly_projection": "amount",
    "monthly_projection": "amount"
  }
}`;

      const response = await this.generateText(prompt);
      
      try {
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          return JSON.parse(jsonMatch[0]);
        } else {
          return {
            capacity_forecast: {
              next_24h: "75%",
              next_week: "85%",
              next_month: "90%"
            },
            collection_optimization: {
              optimal_frequency: "daily",
              next_collection: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(),
              efficiency_score: 0.8
            },
            usage_patterns: {
              peak_hours: ["9:00", "17:00"],
              peak_days: ["Monday", "Friday"],
              seasonal_trends: "Based on AI analysis"
            },
            revenue_forecast: {
              daily_average: "$150",
              weekly_projection: "$1050",
              monthly_projection: "$4500"
            }
          };
        }
      } catch (parseError) {
        return {
          capacity_forecast: {
            next_24h: "75%",
            next_week: "85%",
            next_month: "90%"
          },
          collection_optimization: {
            optimal_frequency: "daily",
            next_collection: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(),
            efficiency_score: 0.8
          },
          usage_patterns: {
            peak_hours: ["9:00", "17:00"],
            peak_days: ["Monday", "Friday"],
            seasonal_trends: "Based on AI analysis"
          },
          revenue_forecast: {
            daily_average: "$150",
            weekly_projection: "$1050",
            monthly_projection: "$4500"
          }
        };
      }
    } catch (error) {
      console.error('Ollama predictive analytics failed:', error.message);
      throw error;
    }
  }

  async chat(message, context = '') {
    if (!this.isAvailable) {
      throw new Error('Ollama service not available');
    }

    try {
      const prompt = context ? `${context}\n\nUser: ${message}\nAssistant:` : `User: ${message}\nAssistant:`;
      return await this.generateText(prompt);
    } catch (error) {
      console.error('Ollama chat failed:', error.message);
      throw error;
    }
  }

  async getAvailableModels() {
    if (!this.isAvailable) {
      return [];
    }

    try {
      const response = await axios.get(`${this.baseURL}/api/tags`);
      return response.data.models || [];
    } catch (error) {
      console.error('Failed to get available models:', error.message);
      return [];
    }
  }

  async pullModel(modelName) {
    if (!this.isAvailable) {
      throw new Error('Ollama service not available');
    }

    try {
      const response = await axios.post(`${this.baseURL}/api/pull`, {
        name: modelName
      });
      return response.data;
    } catch (error) {
      console.error(`Failed to pull model ${modelName}:`, error.message);
      throw error;
    }
  }

  getStatus() {
    return {
      available: this.isAvailable,
      baseURL: this.baseURL,
      defaultModel: this.defaultModel,
      timestamp: new Date().toISOString()
    };
  }
}

module.exports = new OllamaService();
